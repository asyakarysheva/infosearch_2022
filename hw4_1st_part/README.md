## Важное о файлах в этой папке

### О векторизованном корпусе

1. В репозиторий не загружается векторизованный корпус. Совсем никак, даже в сжатом виде. Поэтому прикрепляю ссылку на эмбеддинги, которые лежат на моём гугл диске: https://drive.google.com/file/d/1F1eDdqDQtgfQoB1XkpV3niAPEqYyn-t7/view?usp=sharing

Пожалуйста, напишите мне, если по каким-то причинам эмбеддинги не скачиваются! Доступ к этому файлу я открыла, но в жизни бывает всякое.

### О файле с расширением .ipynb

2. Среди файлов есть такой – `hw4_vectorization.ipynb`. В нём корпус векторизуется с помощью BERT. Векторизовать ответы у себя на компьютере не представлялось возможным. Поэтому я использовала Colab с GPU. Весь необходимый код для векторизации и для сохранения результатов работы модели представлен в файле `hw4_vectorization.ipynb`. Расширение именно такое, потому что, кажется, файлы с таким расширением (а не с `.py`) удобнее запускать на Colab.

### О файле texts_preprocessed.txt

3. В целом запускать модуль `main.py` для того, чтобы получить предобработанные ответы (чтобы, в свою очередь, затем их векторизовать), не очень удобно. Чтобы получить предобработанные ответы, можно закомментить всё в `main.py`, что не относится к их получению. Но это, наверное, всё же неудобно. Поэтому я на всякий случай загрузила предобработанные тексты в репозиторий. При проверке можно будет просто загрузить их отсюда и дать на вход модели.

Очень извиняюсь, что в этот раз всё получилось немного криво-косо, но я, честно говоря, понятия не имею, как иначе (кроме как в Colab с GPU) можно работать с моделью такого размера.

## Инструкция

### Как запускать решение

Чтобы запустить решение, нужно загрузить векторизованный корпус `answers_embeddings.pt`.

Решение запускается через терминал.

Для запуска решения нужно указать 3 аргумента, то есть написать в терминале что-то такое: `python3 main.py путь_до_data.json путь_до_answers_embeddings.pt "запрос"`.

NB! 4ый аргумент закомменчен: он нужен для того, чтобы позже сохранить предобработанные тексты, которые далее подаются на вход модели. Я предполагаю, что это в целом не нужно делать (в репозитории есть предобработанные тексты, а также их эмбеддинги), но (для воспроизводимости) в коде есть всё необходимое для получения предобработанных ответов. (см. пункты 2 и 3 предыдущего раздела).

### Как решение работает верхнеуровнево aka что происходит в `main.py`

1. Через терминал вводятся 3 аргумента – путь до данных, путь до эмбеддингов корпуса и запрос.
2. После этого выполняется функция `main()`, которая принимает на вход запрос.

В функции `main()`:

3. Загружаются ответы с помощью функции `getting_answers` модуля `load_data`.
4. Предобрабатывается запрос (функция `query_preprocessing` модуля `preprocess_data`).
5. Загружается индексированный корпус (функция `computing_index_corpus` модуля `compute_index`).
6. Индексируется предобработанный запрос – используется функция `computing_index_query` модуля `compute_index`.
7. Вычисляется косинусная близость между индексированными корпусом и запросом (функция `computing_similarity` модуля `compute_similarity`).
8. Индексы скоров сортируются в обратном порядке.
9. Ответы сортируются в соответствии с индексами скоров.
10. Выводятся наиболее близкие к запросу ответы.

### Код задокументирован
