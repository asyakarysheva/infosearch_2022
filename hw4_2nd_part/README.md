## Важное о файлах в этой папке

### О векторизованном корпусе

1. В репозиторий не загружается векторизованный корпус (в том числе в сжатом виде). Поэтому прикрепляю ссылку на эмбеддинги, которые лежат на моём гугл диске: https://drive.google.com/file/d/1IjkOZlszR3nqC96cIZ6EemEDm0W04rTk/view?usp=sharing (здесь лежат эмбеддинги ответов), https://drive.google.com/file/d/1-0OVoKKXoL_aIzbSi717NOcUm9Z2oBlE/view?usp=sharing (здесь лежат эмбеддинги вопросов).

Пожалуйста, напишите мне, если по каким-то причинам эмбеддинги не скачиваются! Доступ к этому файлу я открыла, но в жизни бывает всякое.

### О файле с расширением .ipynb

2. Среди файлов есть такой – `hw4_vectorization_part2.ipynb`. В нём ответы и вопросы векторизуются с помощью BERT. Векторизовать их у себя на компьютере не представлялось возможным. Поэтому я использовала Colab с GPU. Весь необходимый код для векторизации и для сохранения результатов работы модели представлен в файле `hw4_vectorization_part2.ipynb`.

### О файлах answers_preprocessed.txt и questions_preprocessed.txt

3. В целом запускать модуль `main.py` для того, чтобы получить предобработанные ответы (чтобы, в свою очередь, затем их векторизовать), не очень удобно. Чтобы получить предобработанные ответы, можно закомментить всё в `main.py`, что не относится к их получению. Но это, наверное, всё же неудобно. Поэтому я на всякий случай загрузила предобработанные ответы и вопросы в репозиторий. При проверке можно будет просто загрузить их отсюда и дать на вход модели.

## Инструкция

### Как запускать решение

Чтобы запустить решение, нужно загрузить векторизованные ответы `answers_embeddings.pt` и вопросы `questions_embeddings.pt`.

Решение запускается через терминал.

Для запуска решения нужно указать 5 аргументов, то есть написать в терминале что-то такое: `python3 main.py путь_до_data.json путь_до_answers_matrix.pkl путь_до_questions_matrix.pkl путь_до_answers_embeddings.pt путь_до_questions_embeddings.pt`.

NB! Есть ещё 2 аргумента, но они закомменчены: они нужны для того, чтобы сохранить предобработанные тексты, которые далее подаются на вход модели. Я предполагаю, что это в целом не нужно делать (в репозитории есть предобработанные ответы и вопросы, а также их эмбеддинги), но (для воспроизводимости) в коде есть всё необходимое для получения предобработанных текстов.

### Как решение работает верхнеуровнево aka что происходит в `main.py`

1. Через терминал вводятся 5 аргументов – путь до данных, путь до матрицы с ответами (с ВМ25), путь до матрицы с вопросами, путь до эмбеддингов ответов и путь до эмбеддингов вопросов.
2. После этого выполняются две функции – `BM_evaluation()` и `BERT_evaluation()`.

В функции `BM_evaluation()`:

3. Загружаются ответы и вопросы.
4. Далее следует условие:

- если матрица с ответами и матрица с вопросами уже существуют, то они подгруждаются с помощью функции `load()` библиотеки `pickle` из пути до них, указанного при вводе аргументов;

- если матриц ещё нет, то они создаются и сохраняются в путь до них, указанный при вводе аргументов.

5. Считается близость между матрицами; сортируются индексы полученных скоров; считается необходимая метрика.

В функции `BERT_evaluation()`:

6. Загружаются посчитанные в Colab эмбеддинги ответов и вопросов.
7. Эмбеддинги приводятся к формату денс матриц.
8. Считается косинусная близость между матрицами; сортируются индексы полученных скоров; считается необходимая метрика.

9. Обе метрики выводятся при запуске программы.

### Код задокументирован
